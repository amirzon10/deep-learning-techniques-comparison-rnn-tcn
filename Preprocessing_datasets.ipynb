{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e623c23b",
   "metadata": {},
   "source": [
    "# Preprocessing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1409c171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "base_dir = 'c:/Users/deepa/Documents/Deeplearning CA/deep-learning-techniques-comparison-rnn-tcn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c19188a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\AppData\\Local\\Temp\\ipykernel_35692\\1142038328.py:24: DtypeWarning: Columns (0: Global_active_power, 1: Global_reactive_power, 2: Voltage, 3: Global_intensity, 4: Sub_metering_1, 5: Sub_metering_2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  power_df = pd.read_csv(os.path.join(power_dir, 'household_power_consumption.csv'), sep=';')\n"
     ]
    }
   ],
   "source": [
    "bike_sharing = fetch_ucirepo(id=275)\n",
    "X_bike = bike_sharing.data.features\n",
    "y_bike = bike_sharing.data.targets\n",
    "bike_df = pd.concat([X_bike, y_bike], axis=1)\n",
    "bike_df = bike_df.drop(columns=['dteday'], errors='ignore')\n",
    "\n",
    "har_dir = os.path.join(base_dir, 'human activity recognition using smartphones')\n",
    "features_raw = []\n",
    "with open(os.path.join(har_dir, 'features.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        features_raw.append(line.strip().split()[1])\n",
    "features = [f\"{f}_{i}\" for i, f in enumerate(features_raw)]\n",
    "\n",
    "X_train_har = pd.read_csv(os.path.join(har_dir, 'train/X_train.txt'), sep='\\s+', header=None, names=features)\n",
    "y_train_har = pd.read_csv(os.path.join(har_dir, 'train/y_train.txt'), sep='\\s+', header=None, names=['activity'])\n",
    "X_test_har = pd.read_csv(os.path.join(har_dir, 'test/X_test.txt'), sep='\\s+', header=None, names=features)\n",
    "y_test_har = pd.read_csv(os.path.join(har_dir, 'test/y_test.txt'), sep='\\s+', header=None, names=['activity'])\n",
    "\n",
    "X_har = pd.concat([X_train_har, X_test_har], ignore_index=True)\n",
    "y_har = pd.concat([y_train_har, y_test_har], ignore_index=True)\n",
    "har_df = pd.concat([X_har, y_har], axis=1)\n",
    "\n",
    "power_dir = os.path.join(base_dir, 'individual household electric power consumption')\n",
    "power_df = pd.read_csv(os.path.join(power_dir, 'household_power_consumption.csv'), sep=';')\n",
    "power_df = power_df.drop(columns=['Date', 'Time'])\n",
    "power_df.replace('?', np.nan, inplace=True)\n",
    "power_df = power_df.ffill().bfill()\n",
    "power_df = power_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8512d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_bike = MinMaxScaler()\n",
    "bike_df_scaled = scaler_bike.fit_transform(bike_df.values)\n",
    "bike_df = pd.DataFrame(bike_df_scaled, columns=bike_df.columns)\n",
    "\n",
    "har_features = har_df.drop(columns=['activity']).values\n",
    "scaler_har = StandardScaler()\n",
    "har_features_scaled = scaler_har.fit_transform(har_features)\n",
    "har_df = pd.concat([pd.DataFrame(har_features_scaled, columns=har_df.drop(columns=['activity']).columns), har_df[['activity']].reset_index(drop=True)], axis=1)\n",
    "\n",
    "scaler_power = MinMaxScaler()\n",
    "power_df_scaled = scaler_power.fit_transform(power_df.values)\n",
    "power_df = pd.DataFrame(power_df_scaled, columns=power_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce9ee4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bike = bike_df.iloc[:, :-1].values\n",
    "y_bike = bike_df.iloc[:, -1].values\n",
    "X_bike_temp, X_bike_test, y_bike_temp, y_bike_test = train_test_split(X_bike, y_bike, test_size=0.2, random_state=seed)\n",
    "X_bike_train, X_bike_val, y_bike_train, y_bike_val = train_test_split(X_bike_temp, y_bike_temp, test_size=0.25, random_state=seed)\n",
    "\n",
    "X_har = har_df.drop(columns=['activity']).values\n",
    "y_har = (har_df['activity'].values - 1).astype(int)\n",
    "X_har_temp, X_har_test, y_har_temp, y_har_test = train_test_split(X_har, y_har, test_size=0.2, random_state=seed)\n",
    "X_har_train, X_har_val, y_har_train, y_har_val = train_test_split(X_har_temp, y_har_temp, test_size=0.25, random_state=seed)\n",
    "\n",
    "n_samples = len(power_df)\n",
    "train_idx = int(0.6 * n_samples)\n",
    "val_idx = int(0.8 * n_samples)\n",
    "power_data = power_df.values\n",
    "X_power_train, X_power_val, X_power_test = power_data[:train_idx], power_data[train_idx:val_idx], power_data[val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8551ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "bike_combined = np.column_stack([np.vstack([X_bike_train, X_bike_val]), np.hstack([y_bike_train, y_bike_val])])\n",
    "X_bike_seq, y_bike_seq = create_sequences(bike_combined, 10)\n",
    "split_idx = int(0.75 * len(X_bike_seq))\n",
    "X_bike_train_seq, X_bike_val_seq = X_bike_seq[:split_idx], X_bike_seq[split_idx:]\n",
    "y_bike_train_seq, y_bike_val_seq = y_bike_seq[:split_idx, -1], y_bike_seq[split_idx:, -1]\n",
    "X_bike_test_seq, y_bike_test_seq = create_sequences(np.column_stack([X_bike_test, y_bike_test]), 10)\n",
    "y_bike_test_seq = y_bike_test_seq[:, -1]\n",
    "\n",
    "har_train_val = np.column_stack([np.vstack([X_har_train, X_har_val]), np.hstack([y_har_train, y_har_val])])\n",
    "X_har_seq, y_har_seq = create_sequences(har_train_val, 128)\n",
    "y_har_seq = y_har_seq[:, -1].astype(int)\n",
    "split_idx = int(0.75 * len(X_har_seq))\n",
    "X_har_train_seq, X_har_val_seq = X_har_seq[:split_idx], X_har_seq[split_idx:]\n",
    "y_har_train_seq, y_har_val_seq = y_har_seq[:split_idx], y_har_seq[split_idx:]\n",
    "har_test = np.column_stack([X_har_test, y_har_test])\n",
    "X_har_test_seq, y_har_test_seq = create_sequences(har_test, 128)\n",
    "y_har_test_seq = y_har_test_seq[:, -1].astype(int)\n",
    "\n",
    "power_combined = np.vstack([X_power_train, X_power_val])\n",
    "X_power_seq, y_power_seq = create_sequences(power_combined, 24)\n",
    "split_idx = int(0.75 * len(X_power_seq))\n",
    "X_power_train_seq, X_power_val_seq = X_power_seq[:split_idx], X_power_seq[split_idx:]\n",
    "y_power_train_seq, y_power_val_seq = y_power_seq[:split_idx], y_power_seq[split_idx:]\n",
    "X_power_test_seq, y_power_test_seq = create_sequences(X_power_test, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "761b20f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Data saved to preprocessed_data/\n"
     ]
    }
   ],
   "source": [
    "preprocessed_dir = os.path.join(base_dir, 'preprocessed_data')\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "bike_data = {\n",
    "    'X_train': X_bike_train, 'X_val': X_bike_val, 'X_test': X_bike_test,\n",
    "    'y_train': y_bike_train, 'y_val': y_bike_val, 'y_test': y_bike_test,\n",
    "    'X_train_seq': X_bike_train_seq, 'X_val_seq': X_bike_val_seq, 'X_test_seq': X_bike_test_seq,\n",
    "    'y_train_seq': y_bike_train_seq, 'y_val_seq': y_bike_val_seq, 'y_test_seq': y_bike_test_seq,\n",
    "    'scaler': scaler_bike\n",
    "}\n",
    "with open(os.path.join(preprocessed_dir, 'bike_sharing.pkl'), 'wb') as f:\n",
    "    pickle.dump(bike_data, f)\n",
    "\n",
    "har_data = {\n",
    "    'X_train': X_har_train, 'X_val': X_har_val, 'X_test': X_har_test,\n",
    "    'y_train': y_har_train, 'y_val': y_har_val, 'y_test': y_har_test,\n",
    "    'X_train_seq': X_har_train_seq, 'X_val_seq': X_har_val_seq, 'X_test_seq': X_har_test_seq,\n",
    "    'y_train_seq': y_har_train_seq, 'y_val_seq': y_har_val_seq, 'y_test_seq': y_har_test_seq,\n",
    "    'scaler': scaler_har\n",
    "}\n",
    "with open(os.path.join(preprocessed_dir, 'har.pkl'), 'wb') as f:\n",
    "    pickle.dump(har_data, f)\n",
    "\n",
    "power_data_pkl = {\n",
    "    'X_train': X_power_train, 'X_val': X_power_val, 'X_test': X_power_test,\n",
    "    'X_train_seq': X_power_train_seq, 'X_val_seq': X_power_val_seq, 'X_test_seq': X_power_test_seq,\n",
    "    'y_train_seq': y_power_train_seq, 'y_val_seq': y_power_val_seq, 'y_test_seq': y_power_test_seq,\n",
    "    'scaler': scaler_power\n",
    "}\n",
    "with open(os.path.join(preprocessed_dir, 'power_consumption.pkl'), 'wb') as f:\n",
    "    pickle.dump(power_data_pkl, f)\n",
    "\n",
    "print(\"Preprocessing complete. Data saved to preprocessed_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc6f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Epochdev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
